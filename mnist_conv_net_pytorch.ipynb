{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying MNIST dataset using convolutional neural network with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Import stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations to apply to the data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])  # 0.1307 and 0.3081 are mean and std of MNIST (after scaling)\n",
    "\n",
    "# Download the data\n",
    "DATA_PATH = '../data'\n",
    "train_set = datasets.MNIST(DATA_PATH, train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST(DATA_PATH, train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8, 1, 4, 6, 3, 4, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "# Function to show an image\n",
    "def imshow(image):\n",
    "    image = image * 0.3081 + 0.1307  # un-normalize\n",
    "    np_image = image.numpy()\n",
    "    plt.imshow(np_image, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "# Get some images\n",
    "mini_loader = torch.utils.data.DataLoader(train_set, batch_size=8, shuffle=True, num_workers=1)\n",
    "images, labels = iter(mini_loader).next()\n",
    "images_grid = utils.make_grid(images).permute(1, 2, 0)\n",
    "\n",
    "# Show the images\n",
    "imshow(images_grid)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class for the convolutional neural network\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(50*4*4, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to train the model over an epoch\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)  # send data to the selected device\n",
    "        optimizer.zero_grad()  # reset parameter gradients\n",
    "        output = model(data)  # perform forward computation\n",
    "        loss = F.cross_entropy(output, target)  # compute loss\n",
    "        loss.backward()  # perform back-propagation\n",
    "        optimizer.step()  # take an optimization step\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item() / len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to evaluate the model\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target).sum().item()\n",
    "            predictions = output.argmax(dim=1)\n",
    "            correct += (predictions == target).sum().item()\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "# Create the optimizer\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 0.035972\n",
      "Train Epoch: 0 [1600/60000 (3%)]\tLoss: 0.033293\n",
      "Train Epoch: 0 [3200/60000 (5%)]\tLoss: 0.024249\n",
      "Train Epoch: 0 [4800/60000 (8%)]\tLoss: 0.011222\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.007369\n",
      "Train Epoch: 0 [8000/60000 (13%)]\tLoss: 0.006698\n",
      "Train Epoch: 0 [9600/60000 (16%)]\tLoss: 0.004295\n",
      "Train Epoch: 0 [11200/60000 (19%)]\tLoss: 0.004092\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.004098\n",
      "Train Epoch: 0 [14400/60000 (24%)]\tLoss: 0.005364\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 0.003406\n",
      "Train Epoch: 0 [17600/60000 (29%)]\tLoss: 0.004747\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.001363\n",
      "Train Epoch: 0 [20800/60000 (35%)]\tLoss: 0.003599\n",
      "Train Epoch: 0 [22400/60000 (37%)]\tLoss: 0.002045\n",
      "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.003190\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.003068\n",
      "Train Epoch: 0 [27200/60000 (45%)]\tLoss: 0.003644\n",
      "Train Epoch: 0 [28800/60000 (48%)]\tLoss: 0.001307\n",
      "Train Epoch: 0 [30400/60000 (51%)]\tLoss: 0.002937\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.002507\n",
      "Train Epoch: 0 [33600/60000 (56%)]\tLoss: 0.002483\n",
      "Train Epoch: 0 [35200/60000 (59%)]\tLoss: 0.002806\n",
      "Train Epoch: 0 [36800/60000 (61%)]\tLoss: 0.001353\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.000897\n",
      "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 0.000610\n",
      "Train Epoch: 0 [41600/60000 (69%)]\tLoss: 0.001887\n",
      "Train Epoch: 0 [43200/60000 (72%)]\tLoss: 0.001902\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.001670\n",
      "Train Epoch: 0 [46400/60000 (77%)]\tLoss: 0.000783\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.002426\n",
      "Train Epoch: 0 [49600/60000 (83%)]\tLoss: 0.004017\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.001136\n",
      "Train Epoch: 0 [52800/60000 (88%)]\tLoss: 0.001532\n",
      "Train Epoch: 0 [54400/60000 (91%)]\tLoss: 0.001987\n",
      "Train Epoch: 0 [56000/60000 (93%)]\tLoss: 0.001654\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.002489\n",
      "Train Epoch: 0 [59200/60000 (99%)]\tLoss: 0.002526\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 9669/10000 (96.7%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.002645\n",
      "Train Epoch: 1 [1600/60000 (3%)]\tLoss: 0.001642\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.001742\n",
      "Train Epoch: 1 [4800/60000 (8%)]\tLoss: 0.001883\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.002601\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.000887\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.002923\n",
      "Train Epoch: 1 [11200/60000 (19%)]\tLoss: 0.000577\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.000960\n",
      "Train Epoch: 1 [14400/60000 (24%)]\tLoss: 0.000947\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.001983\n",
      "Train Epoch: 1 [17600/60000 (29%)]\tLoss: 0.001351\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.001223\n",
      "Train Epoch: 1 [20800/60000 (35%)]\tLoss: 0.002372\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.000389\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.001513\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.001225\n",
      "Train Epoch: 1 [27200/60000 (45%)]\tLoss: 0.000370\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.000749\n",
      "Train Epoch: 1 [30400/60000 (51%)]\tLoss: 0.001321\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.003014\n",
      "Train Epoch: 1 [33600/60000 (56%)]\tLoss: 0.001671\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.000503\n",
      "Train Epoch: 1 [36800/60000 (61%)]\tLoss: 0.000803\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.002578\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.001142\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.000377\n",
      "Train Epoch: 1 [43200/60000 (72%)]\tLoss: 0.001770\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.000429\n",
      "Train Epoch: 1 [46400/60000 (77%)]\tLoss: 0.000177\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.000129\n",
      "Train Epoch: 1 [49600/60000 (83%)]\tLoss: 0.001101\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.000807\n",
      "Train Epoch: 1 [52800/60000 (88%)]\tLoss: 0.000526\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.000843\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.001737\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.000548\n",
      "Train Epoch: 1 [59200/60000 (99%)]\tLoss: 0.000246\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 9835/10000 (98.3%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.000969\n",
      "Train Epoch: 2 [1600/60000 (3%)]\tLoss: 0.000313\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.001712\n",
      "Train Epoch: 2 [4800/60000 (8%)]\tLoss: 0.000675\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.000529\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.000787\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.000371\n",
      "Train Epoch: 2 [11200/60000 (19%)]\tLoss: 0.000769\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.000717\n",
      "Train Epoch: 2 [14400/60000 (24%)]\tLoss: 0.001287\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.000672\n",
      "Train Epoch: 2 [17600/60000 (29%)]\tLoss: 0.000810\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.001609\n",
      "Train Epoch: 2 [20800/60000 (35%)]\tLoss: 0.001310\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.001538\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.000315\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.000293\n",
      "Train Epoch: 2 [27200/60000 (45%)]\tLoss: 0.001421\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.001850\n",
      "Train Epoch: 2 [30400/60000 (51%)]\tLoss: 0.000255\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.000450\n",
      "Train Epoch: 2 [33600/60000 (56%)]\tLoss: 0.001016\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.001190\n",
      "Train Epoch: 2 [36800/60000 (61%)]\tLoss: 0.000965\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.001097\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.001736\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.000256\n",
      "Train Epoch: 2 [43200/60000 (72%)]\tLoss: 0.001337\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.000617\n",
      "Train Epoch: 2 [46400/60000 (77%)]\tLoss: 0.001299\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.000665\n",
      "Train Epoch: 2 [49600/60000 (83%)]\tLoss: 0.000445\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.000554\n",
      "Train Epoch: 2 [52800/60000 (88%)]\tLoss: 0.000499\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.000119\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.001546\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.000703\n",
      "Train Epoch: 2 [59200/60000 (99%)]\tLoss: 0.000083\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 9864/10000 (98.6%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.000213\n",
      "Train Epoch: 3 [1600/60000 (3%)]\tLoss: 0.000854\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.001335\n",
      "Train Epoch: 3 [4800/60000 (8%)]\tLoss: 0.000426\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.000447\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.000268\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.000539\n",
      "Train Epoch: 3 [11200/60000 (19%)]\tLoss: 0.000284\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.000143\n",
      "Train Epoch: 3 [14400/60000 (24%)]\tLoss: 0.000101\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.000121\n",
      "Train Epoch: 3 [17600/60000 (29%)]\tLoss: 0.000361\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.000085\n",
      "Train Epoch: 3 [20800/60000 (35%)]\tLoss: 0.000351\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.000227\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.000858\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.000520\n",
      "Train Epoch: 3 [27200/60000 (45%)]\tLoss: 0.001477\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.000068\n",
      "Train Epoch: 3 [30400/60000 (51%)]\tLoss: 0.000901\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.000802\n",
      "Train Epoch: 3 [33600/60000 (56%)]\tLoss: 0.000698\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.000387\n",
      "Train Epoch: 3 [36800/60000 (61%)]\tLoss: 0.003345\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.000128\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.000115\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.000552\n",
      "Train Epoch: 3 [43200/60000 (72%)]\tLoss: 0.000396\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.000133\n",
      "Train Epoch: 3 [46400/60000 (77%)]\tLoss: 0.000214\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.001044\n",
      "Train Epoch: 3 [49600/60000 (83%)]\tLoss: 0.001055\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.000027\n",
      "Train Epoch: 3 [52800/60000 (88%)]\tLoss: 0.000448\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.001197\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.000835\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.000462\n",
      "Train Epoch: 3 [59200/60000 (99%)]\tLoss: 0.000434\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 9867/10000 (98.7%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.000373\n",
      "Train Epoch: 4 [1600/60000 (3%)]\tLoss: 0.000481\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.000910\n",
      "Train Epoch: 4 [4800/60000 (8%)]\tLoss: 0.000523\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.000641\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.001588\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.000085\n",
      "Train Epoch: 4 [11200/60000 (19%)]\tLoss: 0.000201\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.000160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [14400/60000 (24%)]\tLoss: 0.001222\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.000374\n",
      "Train Epoch: 4 [17600/60000 (29%)]\tLoss: 0.000759\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.000409\n",
      "Train Epoch: 4 [20800/60000 (35%)]\tLoss: 0.001085\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.000468\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.000240\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.000519\n",
      "Train Epoch: 4 [27200/60000 (45%)]\tLoss: 0.000366\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.000181\n",
      "Train Epoch: 4 [30400/60000 (51%)]\tLoss: 0.000045\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.000412\n",
      "Train Epoch: 4 [33600/60000 (56%)]\tLoss: 0.001252\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.000547\n",
      "Train Epoch: 4 [36800/60000 (61%)]\tLoss: 0.001221\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.001510\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.001717\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.000663\n",
      "Train Epoch: 4 [43200/60000 (72%)]\tLoss: 0.000063\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.000170\n",
      "Train Epoch: 4 [46400/60000 (77%)]\tLoss: 0.000784\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.000790\n",
      "Train Epoch: 4 [49600/60000 (83%)]\tLoss: 0.000175\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.000208\n",
      "Train Epoch: 4 [52800/60000 (88%)]\tLoss: 0.000384\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.000189\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.003250\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.000959\n",
      "Train Epoch: 4 [59200/60000 (99%)]\tLoss: 0.000875\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 9880/10000 (98.8%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.000202\n",
      "Train Epoch: 5 [1600/60000 (3%)]\tLoss: 0.000525\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.000072\n",
      "Train Epoch: 5 [4800/60000 (8%)]\tLoss: 0.000155\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.000716\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.000243\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.001818\n",
      "Train Epoch: 5 [11200/60000 (19%)]\tLoss: 0.000503\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.000150\n",
      "Train Epoch: 5 [14400/60000 (24%)]\tLoss: 0.000389\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.000084\n",
      "Train Epoch: 5 [17600/60000 (29%)]\tLoss: 0.000174\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.000558\n",
      "Train Epoch: 5 [20800/60000 (35%)]\tLoss: 0.000119\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.000479\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.000134\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.001222\n",
      "Train Epoch: 5 [27200/60000 (45%)]\tLoss: 0.000171\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.000037\n",
      "Train Epoch: 5 [30400/60000 (51%)]\tLoss: 0.000073\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.000819\n",
      "Train Epoch: 5 [33600/60000 (56%)]\tLoss: 0.001455\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.001084\n",
      "Train Epoch: 5 [36800/60000 (61%)]\tLoss: 0.000715\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.000148\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.000165\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.000936\n",
      "Train Epoch: 5 [43200/60000 (72%)]\tLoss: 0.000166\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.000108\n",
      "Train Epoch: 5 [46400/60000 (77%)]\tLoss: 0.000280\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.000158\n",
      "Train Epoch: 5 [49600/60000 (83%)]\tLoss: 0.000587\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.003035\n",
      "Train Epoch: 5 [52800/60000 (88%)]\tLoss: 0.000998\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.000335\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.000110\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.001153\n",
      "Train Epoch: 5 [59200/60000 (99%)]\tLoss: 0.000053\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9900/10000 (99.0%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.000217\n",
      "Train Epoch: 6 [1600/60000 (3%)]\tLoss: 0.000187\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.000156\n",
      "Train Epoch: 6 [4800/60000 (8%)]\tLoss: 0.002401\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.000036\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 0.000477\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.001339\n",
      "Train Epoch: 6 [11200/60000 (19%)]\tLoss: 0.000354\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.000211\n",
      "Train Epoch: 6 [14400/60000 (24%)]\tLoss: 0.000672\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.000328\n",
      "Train Epoch: 6 [17600/60000 (29%)]\tLoss: 0.000200\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.000208\n",
      "Train Epoch: 6 [20800/60000 (35%)]\tLoss: 0.000530\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.000209\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.000122\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.000162\n",
      "Train Epoch: 6 [27200/60000 (45%)]\tLoss: 0.002982\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.000480\n",
      "Train Epoch: 6 [30400/60000 (51%)]\tLoss: 0.001037\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.000422\n",
      "Train Epoch: 6 [33600/60000 (56%)]\tLoss: 0.000406\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.000092\n",
      "Train Epoch: 6 [36800/60000 (61%)]\tLoss: 0.001217\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.001034\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.000419\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.001357\n",
      "Train Epoch: 6 [43200/60000 (72%)]\tLoss: 0.000142\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.000760\n",
      "Train Epoch: 6 [46400/60000 (77%)]\tLoss: 0.000086\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.000131\n",
      "Train Epoch: 6 [49600/60000 (83%)]\tLoss: 0.000914\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.000839\n",
      "Train Epoch: 6 [52800/60000 (88%)]\tLoss: 0.000727\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.000178\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 0.000371\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.000063\n",
      "Train Epoch: 6 [59200/60000 (99%)]\tLoss: 0.000184\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9889/10000 (98.9%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.000136\n",
      "Train Epoch: 7 [1600/60000 (3%)]\tLoss: 0.000139\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.000157\n",
      "Train Epoch: 7 [4800/60000 (8%)]\tLoss: 0.000631\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.000234\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 0.001361\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.000790\n",
      "Train Epoch: 7 [11200/60000 (19%)]\tLoss: 0.000491\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.000149\n",
      "Train Epoch: 7 [14400/60000 (24%)]\tLoss: 0.000105\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.000134\n",
      "Train Epoch: 7 [17600/60000 (29%)]\tLoss: 0.000186\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.000141\n",
      "Train Epoch: 7 [20800/60000 (35%)]\tLoss: 0.000206\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.000154\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.000331\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.000248\n",
      "Train Epoch: 7 [27200/60000 (45%)]\tLoss: 0.000147\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.000132\n",
      "Train Epoch: 7 [30400/60000 (51%)]\tLoss: 0.001104\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.000467\n",
      "Train Epoch: 7 [33600/60000 (56%)]\tLoss: 0.000833\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.000275\n",
      "Train Epoch: 7 [36800/60000 (61%)]\tLoss: 0.000030\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.000162\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.000452\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.000286\n",
      "Train Epoch: 7 [43200/60000 (72%)]\tLoss: 0.000360\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.001427\n",
      "Train Epoch: 7 [46400/60000 (77%)]\tLoss: 0.000331\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.000306\n",
      "Train Epoch: 7 [49600/60000 (83%)]\tLoss: 0.000224\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.001821\n",
      "Train Epoch: 7 [52800/60000 (88%)]\tLoss: 0.001163\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.002381\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 0.000661\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.000059\n",
      "Train Epoch: 7 [59200/60000 (99%)]\tLoss: 0.000151\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9886/10000 (98.9%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.001677\n",
      "Train Epoch: 8 [1600/60000 (3%)]\tLoss: 0.000110\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.000171\n",
      "Train Epoch: 8 [4800/60000 (8%)]\tLoss: 0.000278\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.000141\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 0.000166\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.000200\n",
      "Train Epoch: 8 [11200/60000 (19%)]\tLoss: 0.000152\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.000171\n",
      "Train Epoch: 8 [14400/60000 (24%)]\tLoss: 0.000084\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.000072\n",
      "Train Epoch: 8 [17600/60000 (29%)]\tLoss: 0.000311\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.000082\n",
      "Train Epoch: 8 [20800/60000 (35%)]\tLoss: 0.000301\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.000125\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.000686\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.000262\n",
      "Train Epoch: 8 [27200/60000 (45%)]\tLoss: 0.000155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.000423\n",
      "Train Epoch: 8 [30400/60000 (51%)]\tLoss: 0.000180\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.000275\n",
      "Train Epoch: 8 [33600/60000 (56%)]\tLoss: 0.000177\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.000460\n",
      "Train Epoch: 8 [36800/60000 (61%)]\tLoss: 0.000165\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.001470\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.000220\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.000731\n",
      "Train Epoch: 8 [43200/60000 (72%)]\tLoss: 0.000240\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.000439\n",
      "Train Epoch: 8 [46400/60000 (77%)]\tLoss: 0.000064\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.000105\n",
      "Train Epoch: 8 [49600/60000 (83%)]\tLoss: 0.000550\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.000066\n",
      "Train Epoch: 8 [52800/60000 (88%)]\tLoss: 0.000159\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.000649\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 0.000338\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.000696\n",
      "Train Epoch: 8 [59200/60000 (99%)]\tLoss: 0.000903\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 9909/10000 (99.1%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.000194\n",
      "Train Epoch: 9 [1600/60000 (3%)]\tLoss: 0.000095\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.000011\n",
      "Train Epoch: 9 [4800/60000 (8%)]\tLoss: 0.000026\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.000650\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 0.000831\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.000065\n",
      "Train Epoch: 9 [11200/60000 (19%)]\tLoss: 0.000068\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.001132\n",
      "Train Epoch: 9 [14400/60000 (24%)]\tLoss: 0.000036\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.000413\n",
      "Train Epoch: 9 [17600/60000 (29%)]\tLoss: 0.000388\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.000260\n",
      "Train Epoch: 9 [20800/60000 (35%)]\tLoss: 0.000091\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.000039\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.000318\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.000078\n",
      "Train Epoch: 9 [27200/60000 (45%)]\tLoss: 0.000103\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.000269\n",
      "Train Epoch: 9 [30400/60000 (51%)]\tLoss: 0.000218\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.000176\n",
      "Train Epoch: 9 [33600/60000 (56%)]\tLoss: 0.001347\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.000141\n",
      "Train Epoch: 9 [36800/60000 (61%)]\tLoss: 0.000036\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.000039\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.000239\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.000470\n",
      "Train Epoch: 9 [43200/60000 (72%)]\tLoss: 0.000258\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.000059\n",
      "Train Epoch: 9 [46400/60000 (77%)]\tLoss: 0.000237\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.000206\n",
      "Train Epoch: 9 [49600/60000 (83%)]\tLoss: 0.000186\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.000244\n",
      "Train Epoch: 9 [52800/60000 (88%)]\tLoss: 0.000019\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.000768\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 0.000057\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.000018\n",
      "Train Epoch: 9 [59200/60000 (99%)]\tLoss: 0.000257\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9905/10000 (99.0%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and test the model\n",
    "n_epochs = 10\n",
    "log_interval = 25\n",
    "for epoch in range(n_epochs):\n",
    "    train(model, device, train_loader, optimizer, epoch, log_interval)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: tensor([4, 4, 8, 2, 4, 4, 8, 9])\n",
      "Predicted: tensor([4, 4, 8, 2, 4, 4, 8, 9], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Get some images\n",
    "mini_loader = torch.utils.data.DataLoader(test_set, batch_size=8, shuffle=True, num_workers=1)\n",
    "images, labels = iter(mini_loader).next()\n",
    "images_grid = utils.make_grid(images).permute(1, 2, 0)\n",
    "\n",
    "# Use the model to predict the labels\n",
    "images = images.to(device)\n",
    "output = model(images)\n",
    "predictions = output.argmax(dim=1)\n",
    "\n",
    "# Show the images\n",
    "imshow(images_grid)\n",
    "print(\"Actual:\", labels)\n",
    "print(\"Predicted:\", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
