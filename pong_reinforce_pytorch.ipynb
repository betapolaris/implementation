{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing Pong Using Only Pixel Values ft. Policy Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Import stuff\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time, os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Set random seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Create directory for tensorlog\n",
    "# Make sure to use a new directory for every new run\n",
    "log_dir = 'logs/pong_pg_1'\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Create the environment\n",
    "env = gym.make(\"Pong-v0\")\n",
    "env.seed(seed)\n",
    "\n",
    "n_actions = env.action_space.n\n",
    "print(n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to grab the current game screen and return it as a 2D numpy array\n",
    "def get_image(env):\n",
    "    image = env.render(mode='rgb_array')\n",
    "    image = image.astype(np.float32) / 255.0  # convert to float and scale to the range [0,1]\n",
    "    image = np.dot(image, [0.299, 0.587, 0.114])  # convert to grayscale\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class for the policy network. Here, we will use a convolutional neural network\n",
    "# that will take an entire screen of game state and suggest an action from that.\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, input_channels=1, input_height=210, input_width=160, output_size=6):\n",
    "        \"\"\"Initialize the network\"\"\"\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=16, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=4, stride=2)\n",
    "        # Can try using pooling layers here\n",
    "        flat_size = 32 * self.conv2d_size_out(self.conv2d_size_out(input_height, 8, 4), 4, 2) * \\\n",
    "                    self.conv2d_size_out(self.conv2d_size_out(input_width, 8, 4), 4, 2)\n",
    "        self.fc1 = nn.Linear(flat_size, 256)\n",
    "        self.fc2 = nn.Linear(256, output_size)\n",
    "        \n",
    "    def conv2d_size_out(self, size, kernel_size, stride):\n",
    "        \"\"\"Utility function to calculate size of dimension after convolution\"\"\"\n",
    "        return (size - (kernel_size - 1) - 1) // stride + 1\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Make a forward pass\"\"\"\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class for the agent\n",
    "class Agent:\n",
    "    def __init__(self, learning_rate=0.001, n_actions=6):\n",
    "        \"\"\"Initialize agent\"\"\"\n",
    "        self.learning_Rate = learning_rate\n",
    "        self.n_actions = n_actions\n",
    "        self.policy = PolicyNetwork().to(device)\n",
    "        self.optimizer = optim.Adam(self.policy.parameters(), lr=learning_rate)\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).unsqueeze(0)\n",
    "        state = state.to(device)\n",
    "        probs = self.policy(state)\n",
    "        action = np.random.choice(self.n_actions, p=probs.to('cpu').detach().squeeze(0).numpy())\n",
    "        log_prob = torch.log(probs.squeeze(0)[action])\n",
    "        return action, log_prob\n",
    "    \n",
    "    def get_probs(self, state):\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).unsqueeze(0)\n",
    "        state = state.to(device)\n",
    "        probs = self.policy(state)\n",
    "        return probs\n",
    "    \n",
    "    def update(self, all_rewards, all_log_probs, discount_rate=0.9):\n",
    "        # Compute discounted rewards\n",
    "        all_discounted_rewards = []\n",
    "        for rewards in all_rewards:\n",
    "            total_reward = 0\n",
    "            discounted_rewards = [0] * len(rewards)\n",
    "            for i in reversed(range(len(rewards))):\n",
    "                discounted_rewards[i] = rewards[i] + discount_rate * total_reward\n",
    "                total_reward = discounted_rewards[i]\n",
    "            all_discounted_rewards.append(discounted_rewards)\n",
    "            \n",
    "        # Stack all rewards and log probs\n",
    "        flat_discounted_rewards = [r for rewards in all_discounted_rewards for r in rewards]\n",
    "        flat_log_probs = [lp for log_probs in all_log_probs for lp in log_probs]\n",
    "        \n",
    "        # Convert to tensors\n",
    "        discounted_rewards = torch.tensor(flat_discounted_rewards).to(device)\n",
    "        log_probs = torch.stack(flat_log_probs).to(device)\n",
    "        \n",
    "        # Normalize rewards, this should speed up training\n",
    "        discounted_rewards = (discounted_rewards - discounted_rewards.mean()) / (discounted_rewards.std() + 1e-9)\n",
    "        \n",
    "        # Reset parameter gradients\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # Compute \"loss\" function\n",
    "        loss = torch.mul(discounted_rewards, -log_probs).sum()\n",
    "        \n",
    "        # Perform backprop\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimize\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def save_parameters(self, path):\n",
    "        torch.save(self.policy.state_dict(), path)\n",
    "        \n",
    "    def load_parameters(self, path):\n",
    "        self.policy.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to simulate an episode\n",
    "def simulate(env, agent, render=False, fps=30, max_steps=10000, detailed=False):\n",
    "    seconds_per_frame = 1 / fps\n",
    "    total_reward = 0\n",
    "    env.reset()\n",
    "    image = get_image(env)\n",
    "    prev_image = image\n",
    "    state = image - prev_image\n",
    "    \n",
    "    for i in range(max_steps):\n",
    "        if render:\n",
    "            env.render()\n",
    "            time.sleep(seconds_per_frame)\n",
    "            \n",
    "        if detailed:\n",
    "            probs = agent.get_probs(state)\n",
    "            print(probs)\n",
    "            \n",
    "        action, log_prob = agent.get_action(state)\n",
    "        _, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        \n",
    "        if done:\n",
    "            env.close()\n",
    "            break\n",
    "        else:\n",
    "            prev_image = image\n",
    "            image = get_image(env)\n",
    "            state = image - prev_image\n",
    "            \n",
    "    print(\"Simulation complete - total reward:\", total_reward)\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters loaded successfully\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0d2213f186ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprev_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-135ab33b2b5c>\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Agent hyperparameters\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Initialize the agent\n",
    "agent = Agent(learning_rate)\n",
    "\n",
    "# Training hyperparameters\n",
    "n_epochs = 100\n",
    "episodes_per_epoch = 3\n",
    "max_steps = 10000\n",
    "discount_rate = 0.95\n",
    "\n",
    "# Autosave settings\n",
    "save_parameters = True\n",
    "save_interval = 10\n",
    "save_path = 'models/pg_pong.pth'\n",
    "load_parameters_before_training = True\n",
    "\n",
    "# Option to show the agent in training\n",
    "show_simulation = False\n",
    "epoch_per_simulation = 25\n",
    "\n",
    "if load_parameters_before_training and os.path.exists(save_path):\n",
    "    agent.load_parameters(save_path)\n",
    "    print(\"Parameters loaded successfully\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    all_rewards = []\n",
    "    all_log_probs = []\n",
    "    total_reward = 0\n",
    "    \n",
    "    for episode in range(episodes_per_epoch):\n",
    "        rewards = []\n",
    "        log_probs = []\n",
    "        \n",
    "        env.reset()\n",
    "        image = get_image(env)\n",
    "        prev_image = image\n",
    "        state = image - prev_image\n",
    "        for step in range(max_steps):\n",
    "            action, log_prob = agent.get_action(state)\n",
    "            _, reward, done, _ = env.step(action)\n",
    "            rewards.append(reward)\n",
    "            log_probs.append(log_prob)\n",
    "            total_reward += reward\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "            else:\n",
    "                preev_image = image\n",
    "                image = get_image(env)\n",
    "                state = image - prev_image\n",
    "                \n",
    "        all_rewards.append(rewards)\n",
    "        all_log_probs.append(log_probs)\n",
    "        \n",
    "    # Update the policy\n",
    "    agent.update(all_rewards, all_log_probs, discount_rate)\n",
    "    \n",
    "    # Track average rewards in TensorBoard\n",
    "    writer.add_scalar('average_reward', total_reward / episodes_per_epoch, epoch)\n",
    "    \n",
    "    # Save model parameters\n",
    "    if save_parameters:\n",
    "        if epoch % save_interval == 0:\n",
    "            agent.save_parameters(save_path)\n",
    "    \n",
    "    # Simulate agent (optional)\n",
    "    if show_simulation and epoch % epoch_per_simulation == 0:\n",
    "        simulate(env, agent, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(avg_rewards)\n",
    "plt.title(\"Agent's performance over time\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average reward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1589, 0.1665, 0.1557, 0.1600, 0.1689, 0.1899]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1650, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1650, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1690, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1650, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1690, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1652, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1650, 0.1580, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1652, 0.1578, 0.1629, 0.1690, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1652, 0.1578, 0.1629, 0.1690, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1652, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1652, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1580, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1652, 0.1578, 0.1629, 0.1690, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1690, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1650, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1580, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1650, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1580, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1650, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1625, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1580, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1652, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1650, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1627, 0.1650, 0.1580, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1690, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1580, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1580, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1690, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1652, 0.1578, 0.1629, 0.1690, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1580, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1650, 0.1580, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1650, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1650, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1580, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1628, 0.1690, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1650, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1652, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1690, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1650, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1650, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1578, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1578, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1629, 0.1691, 0.1825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1630, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1626, 0.1651, 0.1579, 0.1630, 0.1690, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1824]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1627, 0.1651, 0.1579, 0.1629, 0.1691, 0.1823]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Simulation complete - total reward: -19.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-19.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate(env, agent, render=True, detailed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
